#!/usr/bin/env python
"""
Cross-Subject Pretraining Script for EEG-BCI Project.

Trains a model on combined data from multiple subjects, creating a
pretrained model that can be finetuned on individual subjects.

Features:
- Saves JSON results to results/ directory
- Generates visualization plots (with optional historical comparison)
- Supports within-subject historical data as baseline

Usage:
    # Train on all available subjects (default)
    uv run python scripts/run_cross_subject.py --model eegnet

    # Train on specific subjects
    uv run python scripts/run_cross_subject.py --model cbramod --subjects S01 S02 S03 S04 S05

    # Motor Execution paradigm
    uv run python scripts/run_cross_subject.py --model eegnet --paradigm movement

    # Custom training parameters
    uv run python scripts/run_cross_subject.py --model eegnet --epochs 100 --batch-size 256

    # Without WandB logging (default: enabled)
    uv run python scripts/run_cross_subject.py --model eegnet --no-wandb

    # Use specific scheduler
    uv run python scripts/run_cross_subject.py --model cbramod --scheduler wsd

    # Suppress plot generation
    uv run python scripts/run_cross_subject.py --model eegnet --no-plot

    # Disable historical comparison in plots
    uv run python scripts/run_cross_subject.py --model eegnet --no-historical
"""

import argparse
import logging
import sys
from datetime import datetime
from pathlib import Path

# Add project root to path (scripts/experiments/ -> scripts/ -> project root)
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from src.utils.device import set_seed, check_cuda_available, get_device
from src.utils.logging import setup_logging
from scripts._training_utils import discover_subjects
from src.training.train_cross_subject import train_cross_subject
from src.config.training import SCHEDULER_PRESETS
from src.results import (
    save_cross_subject_result,
    find_compatible_within_subject_results,
    generate_result_filename,
)
from src.visualization import generate_cross_subject_single_plot


setup_logging('cross_subject')
logger = logging.getLogger(__name__)


def main():
    parser = argparse.ArgumentParser(
        description='Cross-subject pretraining for EEG-BCI',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
Examples:
  # Train EEGNet on all subjects
  uv run python scripts/run_cross_subject.py --model eegnet

  # Train CBraMod on specific subjects
  uv run python scripts/run_cross_subject.py --model cbramod --subjects S01 S02 S03

  # Motor Execution paradigm with custom epochs
  uv run python scripts/run_cross_subject.py --model eegnet --paradigm movement --epochs 100

  # Without WandB and with custom scheduler
  uv run python scripts/run_cross_subject.py --model cbramod --no-wandb --scheduler wsd
'''
    )

    # Required arguments
    parser.add_argument(
        '--model', type=str, required=True,
        choices=['eegnet', 'cbramod'],
        help='Model type to train'
    )

    # Data arguments
    parser.add_argument(
        '--data-root', type=str, default='data',
        help='Path to data directory (default: data)'
    )
    parser.add_argument(
        '--subjects', nargs='+', default=None,
        help='Specific subjects to train on (default: all available)'
    )
    parser.add_argument(
        '--paradigm', type=str, default='imagery',
        choices=['imagery', 'movement'],
        help='Experiment paradigm (default: imagery)'
    )
    parser.add_argument(
        '--task', type=str, default='binary',
        choices=['binary', 'ternary', 'quaternary'],
        help='Classification task (default: binary)'
    )

    # Training arguments
    parser.add_argument(
        '--epochs', type=int, default=None,
        help='Number of training epochs (default: 50 for EEGNet, 100 for CBraMod)'
    )
    parser.add_argument(
        '--batch-size', type=int, default=None,
        help='Batch size (default: 128 for EEGNet, 256 for CBraMod)'
    )
    parser.add_argument(
        '--seed', type=int, default=42,
        help='Random seed (default: 42)'
    )
    parser.add_argument(
        '--scheduler', type=str, default=None,
        choices=list(SCHEDULER_PRESETS.keys()),
        help='Learning rate scheduler (default: model-specific)'
    )
    parser.add_argument(
        '--config', type=str, default=None, metavar='YAML_PATH',
        help='YAML 配置文件路径 (覆盖模型默认配置，被 CLI 参数覆盖)'
    )

    # Output arguments
    parser.add_argument(
        '--output-dir', type=str, default='checkpoints/cross_subject',
        help='Directory to save pretrained model (default: checkpoints/cross_subject)'
    )
    parser.add_argument(
        '--results-dir', type=str, default='results',
        help='Directory to save JSON results and plots (default: results)'
    )
    parser.add_argument(
        '--no-plot', action='store_true',
        help='Suppress plot generation (plots are generated by default)'
    )
    parser.add_argument(
        '--no-historical', action='store_true',
        help='Disable historical data retrieval for plot comparison'
    )

    # Cache arguments
    parser.add_argument(
        '--cache-only', action='store_true',
        help='Load data exclusively from cache index (no filesystem scan)'
    )
    parser.add_argument(
        '--cache-index-path', type=str, default='.cache_index.json',
        help='Path to cache index file (default: .cache_index.json)'
    )

    # WandB arguments
    parser.add_argument(
        '--no-wandb', action='store_true',
        help='Disable WandB logging (default: enabled)'
    )
    parser.add_argument(
        '--wandb-project', type=str, default='eeg-bci',
        help='WandB project name (default: eeg-bci)'
    )
    parser.add_argument(
        '--wandb-entity', type=str, default=None,
        help='WandB entity (team/username)'
    )
    parser.add_argument(
        '--wandb-group', type=str, default=None,
        help='WandB run group'
    )
    parser.add_argument(
        '--upload-model', action='store_true',
        help='Upload model artifacts to WandB'
    )

    # Verbosity arguments
    parser.add_argument(
        '--verbose', '-v', type=int, default=2,
        choices=[0, 1, 2],
        help='Verbosity level: 0=silent, 1=minimal, 2=full (default: 2)'
    )
    parser.add_argument(
        '--quiet', '-q', action='store_true',
        help='Equivalent to --verbose 0'
    )

    args = parser.parse_args()

    # Handle verbosity
    verbose = 0 if args.quiet else args.verbose

    # Check GPU
    check_cuda_available(required=True)
    device = get_device()
    logger.info(f"Device: {device}")

    # Set seed
    set_seed(args.seed)
    logger.info(f"Seed: {args.seed}")

    # Discover subjects if not specified
    if args.subjects:
        subjects = args.subjects
    else:
        subjects = discover_subjects(
            args.data_root,
            args.paradigm,
            args.task,
            cache_only=args.cache_only,
            cache_index_path=args.cache_index_path
        )

    if not subjects:
        logger.error(f"No subjects found in {args.data_root}")
        sys.exit(1)

    logger.info(f"Model: {args.model.upper()}")
    logger.info(f"Paradigm: {args.paradigm}")
    logger.info(f"Task: {args.task}")
    logger.info(f"Subjects: {subjects}")

    # Build merged config_overrides: YAML → CLI scheduler override
    from src.config.training import load_yaml_config
    config_overrides = load_yaml_config(args.config) if args.config else {}
    if args.scheduler:
        config_overrides.setdefault('training', {})['scheduler'] = args.scheduler
    config_overrides = config_overrides or None

    # Generate run tag
    run_tag = datetime.now().strftime("%Y%m%d_%H%M")

    # Run cross-subject training
    results = train_cross_subject(
        subjects=subjects,
        model_type=args.model,
        task=args.task,
        paradigm=args.paradigm,
        epochs=args.epochs,
        batch_size=args.batch_size,
        save_dir=args.output_dir,
        data_root=args.data_root,
        device=device,
        seed=args.seed,
        config_overrides=config_overrides,
        cache_only=args.cache_only,
        wandb_enabled=not args.no_wandb,
        upload_model=args.upload_model,
        wandb_project=args.wandb_project,
        wandb_entity=args.wandb_entity,
        wandb_group=args.wandb_group,
        verbose=verbose,
    )

    # Save JSON results to results/ directory
    results_path = save_cross_subject_result(
        result=results,
        model_type=args.model,
        paradigm=args.paradigm,
        task=args.task,
        output_dir=args.results_dir,
        run_tag=run_tag,
    )
    logger.info(f"Results saved: {results_path}")

    # Generate visualization
    if not args.no_plot:
        # Search for within-subject historical data (optional)
        historical_within_subject = None
        if not args.no_historical:
            historical_within_subject = find_compatible_within_subject_results(
                output_dir=args.results_dir,
                paradigm=args.paradigm,
                task=args.task,
                subjects=subjects,
            )
            if historical_within_subject:
                logger.info(f"Found within-subject historical data: {historical_within_subject.get('source_file', 'unknown')}")

        # Generate plot
        plot_filename = generate_result_filename(
            args.model, args.paradigm, args.task, 'png', run_tag, is_cross_subject=True
        )
        plot_path = Path(args.results_dir) / plot_filename

        generate_cross_subject_single_plot(
            result=results,
            model_type=args.model,
            output_path=str(plot_path),
            task_type=args.task,
            paradigm=args.paradigm,
            historical_within_subject=historical_within_subject,
        )
        logger.info(f"Plot saved: {plot_path}")

    # Print final summary
    if verbose >= 1:
        print("\n" + "=" * 70)
        print(" CROSS-SUBJECT PRETRAINING COMPLETE")
        print("=" * 70)
        print(f"  Model saved: {results['model_path']}")
        print(f"  Results JSON: {results_path}")
        print(f"  Mean test acc: {results['mean_test_acc']:.2%} +/- {results['std_test_acc']:.2%}")
        print(f"  Best val acc: {results['val_acc']:.2%}")
        print(f"  Training time: {results['training_time']:.1f}s")
        print("\n  Per-subject test accuracy:")
        for subject_id, acc in sorted(results['per_subject_test_acc'].items()):
            print(f"    {subject_id}: {acc:.2%}")
        print("=" * 70)

    return 0


if __name__ == '__main__':
    sys.exit(main())
