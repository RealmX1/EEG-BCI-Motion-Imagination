{
  "metadata": {
    "paradigm": "imagery",
    "paradigm_description": "Motor Imagery (MI)",
    "task_type": "ternary",
    "run_tag": "20260204_1837",
    "timestamp": "2026-02-04T19:59:28.188744",
    "n_subjects": 21
  },
  "models": {
    "cbramod": {
      "subjects": [
        {
          "subject_id": "S01",
          "task_type": "ternary",
          "model_type": "cbramod",
          "best_val_acc": 0.47954055994257,
          "test_acc": 0.5416666666666666,
          "test_acc_majority": 0.5416666666666666,
          "epochs_trained": 27,
          "training_time": 246.76337559999956
        },
        {
          "subject_id": "S02",
          "task_type": "ternary",
          "model_type": "cbramod",
          "best_val_acc": 0.5518227305218013,
          "test_acc": 0.7791666666666667,
          "test_acc_majority": 0.7791666666666667,
          "epochs_trained": 27,
          "training_time": 244.45076979999794
        },
        {
          "subject_id": "S03",
          "task_type": "ternary",
          "model_type": "cbramod",
          "best_val_acc": 0.5584229390681004,
          "test_acc": 0.8291666666666667,
          "test_acc_majority": 0.8291666666666667,
          "epochs_trained": 20,
          "training_time": 195.28532149999955
        },
        {
          "subject_id": "S04",
          "task_type": "ternary",
          "model_type": "cbramod",
          "best_val_acc": 0.4703856749311295,
          "test_acc": 0.8625,
          "test_acc_majority": 0.8625,
          "epochs_trained": 24,
          "training_time": 229.92043340000237
        },
        {
          "subject_id": "S05",
          "task_type": "ternary",
          "model_type": "cbramod",
          "best_val_acc": 0.4509668508287293,
          "test_acc": 0.5416666666666666,
          "test_acc_majority": 0.5416666666666666,
          "epochs_trained": 44,
          "training_time": 350.5255916999995
        },
        {
          "subject_id": "S06",
          "task_type": "ternary",
          "model_type": "cbramod",
          "best_val_acc": 0.5579053373615307,
          "test_acc": 0.7625,
          "test_acc_majority": 0.7625,
          "epochs_trained": 18,
          "training_time": 134.42798949999997
        },
        {
          "subject_id": "S07",
          "task_type": "ternary",
          "model_type": "cbramod",
          "best_val_acc": 0.5464285714285714,
          "test_acc": 0.6791666666666667,
          "test_acc_majority": 0.6791666666666667,
          "epochs_trained": 25,
          "training_time": 224.7017995999995
        },
        {
          "subject_id": "S08",
          "task_type": "ternary",
          "model_type": "cbramod",
          "best_val_acc": 0.539454806312769,
          "test_acc": 0.7666666666666667,
          "test_acc_majority": 0.7666666666666667,
          "epochs_trained": 22,
          "training_time": 208.07453539999915
        },
        {
          "subject_id": "S09",
          "task_type": "ternary",
          "model_type": "cbramod",
          "best_val_acc": 0.6914817465998568,
          "test_acc": 0.8458333333333333,
          "test_acc_majority": 0.8458333333333333,
          "epochs_trained": 19,
          "training_time": 186.18915019999986
        },
        {
          "subject_id": "S10",
          "task_type": "ternary",
          "model_type": "cbramod",
          "best_val_acc": 0.39226914817465997,
          "test_acc": 0.42083333333333334,
          "test_acc_majority": 0.42083333333333334,
          "epochs_trained": 15,
          "training_time": 163.97032059999765
        },
        {
          "subject_id": "S11",
          "task_type": "ternary",
          "model_type": "cbramod",
          "best_val_acc": 0.5164992826398852,
          "test_acc": 0.6541666666666667,
          "test_acc_majority": 0.6541666666666667,
          "epochs_trained": 27,
          "training_time": 235.1657367000007
        },
        {
          "subject_id": "S12",
          "task_type": "ternary",
          "model_type": "cbramod",
          "best_val_acc": 0.49569583931133426,
          "test_acc": 0.5958333333333333,
          "test_acc_majority": 0.5958333333333333,
          "epochs_trained": 16,
          "training_time": 174.585087200001
        },
        {
          "subject_id": "S13",
          "task_type": "ternary",
          "model_type": "cbramod",
          "best_val_acc": 0.49437412095639943,
          "test_acc": 0.7333333333333333,
          "test_acc_majority": 0.7333333333333333,
          "epochs_trained": 28,
          "training_time": 254.058466399998
        },
        {
          "subject_id": "S14",
          "task_type": "ternary",
          "model_type": "cbramod",
          "best_val_acc": 0.49171270718232046,
          "test_acc": 0.7208333333333333,
          "test_acc_majority": 0.7208333333333333,
          "epochs_trained": 33,
          "training_time": 285.7233516999986
        },
        {
          "subject_id": "S15",
          "task_type": "ternary",
          "model_type": "cbramod",
          "best_val_acc": 0.5228215767634855,
          "test_acc": 0.5416666666666666,
          "test_acc_majority": 0.5416666666666666,
          "epochs_trained": 32,
          "training_time": 270.88596490000054
        },
        {
          "subject_id": "S16",
          "task_type": "ternary",
          "model_type": "cbramod",
          "best_val_acc": 0.45147969717825187,
          "test_acc": 0.6166666666666667,
          "test_acc_majority": 0.6166666666666667,
          "epochs_trained": 45,
          "training_time": 352.6284139999989
        },
        {
          "subject_id": "S17",
          "task_type": "ternary",
          "model_type": "cbramod",
          "best_val_acc": 0.5616815988973122,
          "test_acc": 0.8166666666666667,
          "test_acc_majority": 0.8166666666666667,
          "epochs_trained": 20,
          "training_time": 199.92061000000103
        },
        {
          "subject_id": "S18",
          "task_type": "ternary",
          "model_type": "cbramod",
          "best_val_acc": 0.4862068965517241,
          "test_acc": 0.6166666666666667,
          "test_acc_majority": 0.6166666666666667,
          "epochs_trained": 21,
          "training_time": 202.68117839999832
        },
        {
          "subject_id": "S19",
          "task_type": "ternary",
          "model_type": "cbramod",
          "best_val_acc": 0.7361878453038674,
          "test_acc": 0.9208333333333333,
          "test_acc_majority": 0.9208333333333333,
          "epochs_trained": 35,
          "training_time": 289.4754584000002
        },
        {
          "subject_id": "S20",
          "task_type": "ternary",
          "model_type": "cbramod",
          "best_val_acc": 0.4100274725274725,
          "test_acc": 0.425,
          "test_acc_majority": 0.425,
          "epochs_trained": 22,
          "training_time": 212.58283519999895
        },
        {
          "subject_id": "S21",
          "task_type": "ternary",
          "model_type": "cbramod",
          "best_val_acc": 0.4476584022038568,
          "test_acc": 0.6125,
          "test_acc_majority": 0.6125,
          "epochs_trained": 21,
          "training_time": 205.04948879999938
        }
      ],
      "summary": {
        "mean": 0.6801587301587302,
        "std": 0.13772471273471004,
        "min": 0.42083333333333334,
        "max": 0.9208333333333333
      }
    }
  },
  "comparison": null
}