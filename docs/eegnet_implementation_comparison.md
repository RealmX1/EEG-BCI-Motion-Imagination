# EEGNet å®ç°å¯¹æ¯”æ–‡æ¡£

æœ¬æ–‡æ¡£è¯¦ç»†å¯¹æ¯”æœ¬ä»“åº“çš„ EEGNet å®ç°ä¸åŸå§‹ FINGER-EEG-BCI è®ºæ–‡å®ç°ä¹‹é—´çš„å·®å¼‚ã€‚

**åŸè®ºæ–‡**: Ding et al., "EEG-based brain-computer interface enables real-time robotic hand control at individual finger level", Nature Communications, 2025

**åŸè®ºæ–‡ä»£ç **: https://github.com/bfinl/Finger-BCI-Decoding

---

## æ¦‚è¿°

| æ–¹é¢ | åŸè®ºæ–‡å®ç° | æœ¬ä»“åº“å®ç° | å·®å¼‚è¯´æ˜ |
|------|-----------|-----------|----------|
| æ·±åº¦å­¦ä¹ æ¡†æ¶ | TensorFlow/Keras | PyTorch | âš ï¸ ä¸åŒæ¡†æ¶ |
| æ¨¡å‹æ¶æ„ | EEGNet-8,2 | EEGNet-8,2 | âœ… ä¸€è‡´ |
| é€šé“æ•° | 128 (BioSemi) | 128 (BioSemi) | âœ… ä¸€è‡´ |
| é‡‡æ ·ç‡ | 1024 Hz â†’ 100 Hz | 1024 Hz â†’ 100 Hz | âœ… ä¸€è‡´ |
| å¸¦é€šæ»¤æ³¢ | 4-40 Hz, 4é˜¶ Butterworth | 4-40 Hz, 4é˜¶ Butterworth | âœ… ä¸€è‡´ |
| æ»‘åŠ¨çª—å£ | 1s çª—å£, 128 samples æ­¥é•¿ | 1s çª—å£, 128 samples æ­¥é•¿ | âœ… ä¸€è‡´ |
| å½’ä¸€åŒ– | Z-score (æ—¶é—´è½´) | Z-score (æ—¶é—´è½´) | âœ… ä¸€è‡´ |
| CAR | æ˜¯ (trial çº§åˆ«) | æ˜¯ (trial çº§åˆ«) | âœ… ä¸€è‡´ |
| Batch Size | 16 | 64 | âš ï¸ ä¸åŒ |
| è®­ç»ƒ epochs | 300 | 300 | âœ… ä¸€è‡´ |
| æ—©åœ patience | 80 | 4-5 | âš ï¸ ä¸åŒ |
| å­¦ä¹ ç‡è°ƒåº¦å™¨ | ReduceLROnPlateau | ReduceLROnPlateau | âœ… ä¸€è‡´ |
| Temporal Kernel | 32 | 64 | âš ï¸ ä¸åŒ |
| æ€§èƒ½ä¼˜åŒ– | æ—  | AMP, torch.compile, cuDNN | ğŸš€ å¢å¼º |

---

## æ¨¡å‹æ¶æ„

### åŸè®ºæ–‡ EEGNet-8,2

**æ–‡ä»¶**: `EEGModels_tf.py`, `Functions.py:219-221`

```python
model = EEGNet(
    nb_classes = params['nclass'],
    Chans = chans,
    Samples = samples,
    dropoutRate = 0.5,      # é¢„è®­ç»ƒ: 0.5, å¾®è°ƒ: 0.65
    kernLength = 32,        # æ³¨æ„: 32 samples @ 100Hz = 320ms
    F1 = 8,
    D = 2,
    F2 = 16,
    dropoutType = 'Dropout'
)
```

**æ¶æ„ç»†èŠ‚** (`EEGModels_tf.py:55-155`):
```
Block 1:
- Conv2D: (1, kernLength=32), F1=8, padding='same', bias=False
- BatchNorm
- DepthwiseConv2D: (Chans, 1), D=2, max_norm(1.)
- BatchNorm
- ELU
- AvgPool2D: (1, 4)
- Dropout: 0.5

Block 2:
- SeparableConv2D: (1, 16), F2=16, padding='same', bias=False
- BatchNorm
- ELU
- AvgPool2D: (1, 8)
- Dropout: 0.5

Classification:
- Flatten
- Dense: n_classes, max_norm(0.25)
- Softmax
```

### æœ¬ä»“åº“å®ç°

**æ–‡ä»¶**: `src/models/eegnet.py:34-130`

```python
class EEGNet(nn.Module):
    def __init__(
        self,
        n_channels: int = 128,
        n_samples: int = 400,       # 4s @ 100Hz
        n_classes: int = 2,
        F1: int = 8,
        D: int = 2,
        F2: int = 16,
        kernel_length: int = 64,    # æ³¨æ„: 64 samples @ 100Hz = 640ms
        dropout_rate: float = 0.5,
    ):
```

**æ¶æ„ç»†èŠ‚**:
```
Block 1:
- Conv2d: (1, kernel_length=64), F1=8, padding='same', bias=False
- BatchNorm2d
- Conv2dWithConstraint: (n_channels, 1), groups=F1, max_norm=1.0
- BatchNorm2d
- ELU
- AvgPool2d: (1, 4)
- Dropout: 0.5

Block 2:
- Conv2d (depthwise): (1, 16), groups=F1*D, bias=False
- Conv2d (pointwise): (1, 1), F2=16, bias=False
- BatchNorm2d
- ELU
- AvgPool2d: (1, 8)
- Dropout: 0.5

Classification:
- Flatten
- Linear: n_classes
```

### æ¶æ„å·®å¼‚åˆ†æ

| å‚æ•° | åŸè®ºæ–‡ | æœ¬ä»“åº“ | å·®å¼‚è¯´æ˜ |
|------|--------|--------|----------|
| F1 | 8 | 8 | âœ… ä¸€è‡´ |
| D | 2 | 2 | âœ… ä¸€è‡´ |
| F2 | 16 | 16 | âœ… ä¸€è‡´ |
| **kernLength** | **32** | **64** | âš ï¸ æœ¬ä»“åº“æ›´é•¿ |
| Pool1 | (1, 4) | (1, 4) | âœ… ä¸€è‡´ |
| Pool2 | (1, 8) | (1, 8) | âœ… ä¸€è‡´ |
| SeparableConv kernel | (1, 16) | (1, 16) | âœ… ä¸€è‡´ |
| Dropout | 0.5 | 0.5 | âœ… ä¸€è‡´ |
| Dense max_norm | 0.25 | æ—  | âš ï¸ æœ¬ä»“åº“æ— çº¦æŸ |
| Depthwise max_norm | 1.0 | 1.0 | âœ… ä¸€è‡´ |

**å…³é”®å·®å¼‚**:
1. **kernLength**: åŸè®ºæ–‡ä½¿ç”¨ 32 (320ms @ 100Hz)ï¼Œæœ¬ä»“åº“ä½¿ç”¨ 64 (640ms @ 100Hz)
2. **Dense layer constraint**: åŸè®ºæ–‡ä½¿ç”¨ max_norm(0.25)ï¼Œæœ¬ä»“åº“æ— çº¦æŸ

---

## æ•°æ®é¢„å¤„ç†

### åŸè®ºæ–‡é¢„å¤„ç†æµç¨‹

**æ–‡ä»¶**: `Functions.py:81-200`

```python
# 1. åŠ è½½æ•°æ®å¹¶æå– trials (line 94-136)
for filepath in data_paths:
    for filename in os.listdir(filepath):
        mat = scipy.io.loadmat(file_path)
        # æå– Target åˆ° TrialEnd ä¹‹é—´çš„æ•°æ®
        # å¡«å……è‡³ maxtriallen=5s (NaN)

        # CAR (é€ trial, line 133)
        cur_data = cur_data - cur_data.mean(axis=1, keepdims=True)

# 2. éšæœºæ‰“ä¹±å¹¶åˆ’åˆ† (line 160-170)
shuffled_idx = np.random.permutation(nTrial)
train_percent = 0.8
train_idx = shuffled_idx[:int(train_percent*nTrial)]

# 3. æ»‘åŠ¨çª—å£åˆ†å‰² (line 177-180)
segment_size = int(params['windowlen'] * params['srate'])  # 1s = 1024 samples
step_size = 128  # 128 samples @ 1024 Hz = 125ms
X_train, Y_train, I_train = segment_data(X_train, Y_train, segment_size, step_size)

# 4. é™é‡‡æ · (line 183-184)
DesiredLen = int(params['windowlen'] * params['downsrate'])  # 100 samples
X_train = resample(X_train, DesiredLen, axis=2)

# 5. å¸¦é€šæ»¤æ³¢ (line 187-196)
padding_length = 100
padded_train = np.pad(X_train, ((0,0),(0,0),(padding_length,padding_length)), 'constant')
b, a = scipy.signal.butter(4, params['bandpass_filt'], btype='bandpass', fs=100)
X_train = scipy.signal.lfilter(b, a, padded_train, axis=-1)
X_train = X_train[:,:,padding_length:-padding_length]

# 6. Z-score å½’ä¸€åŒ– (line 199-200)
X_train = scipy.stats.zscore(X_train, axis=2, nan_policy='omit')
```

### æœ¬ä»“åº“å®ç°

**æ–‡ä»¶**: `src/preprocessing/data_loader.py:721-835`

```python
def preprocess_run_paper_aligned(...):
    # Step 1: æå– trials (line 757-803)
    # åŸºäº Target/TrialEnd äº‹ä»¶ï¼Œå¡«å……è‡³ max_samples (NaN)

    # Step 2: CAR (é€ trial, line 806-807)
    if config.apply_car:
        trials = trials - trials.mean(axis=1, keepdims=True)

    # Step 3: æ»‘åŠ¨çª—å£åˆ†å‰² (line 809-815)
    segment_size = int(config.segment_length * fs)  # 1024 samples
    step_size = config.segment_step_samples  # 128 samples
    segments, seg_labels, trial_indices = segment_with_sliding_window(...)

    # Step 4: é™é‡‡æ · (line 817-820)
    target_samples = int(config.segment_length * config.target_fs)  # 100
    segments = scipy.signal.resample(segments, target_samples, axis=2)

    # Step 5: å¸¦é€šæ»¤æ³¢ (line 822-830)
    segments = apply_bandpass_filter_paper(
        segments, fs=100, low_freq=4.0, high_freq=40.0, order=4, padding=100
    )

    # Step 6: Z-score å½’ä¸€åŒ– (line 832-833)
    segments = apply_zscore_per_segment(segments, axis=-1)
```

### é¢„å¤„ç†å·®å¼‚åˆ†æ

| æ­¥éª¤ | åŸè®ºæ–‡ | æœ¬ä»“åº“ | çŠ¶æ€ |
|------|--------|--------|------|
| Trial æå– | Target â†’ TrialEnd | Target â†’ TrialEnd | âœ… ä¸€è‡´ |
| å¡«å……æ–¹æ³• | NaN | NaN | âœ… ä¸€è‡´ |
| CAR åº”ç”¨ | é€ trial (axis=1) | é€ trial (axis=1) | âœ… ä¸€è‡´ |
| æ»‘åŠ¨çª—å£ | 1s @ 1024Hz | 1s @ 1024Hz | âœ… ä¸€è‡´ |
| æ­¥é•¿ | 128 samples | 128 samples | âœ… ä¸€è‡´ |
| é™é‡‡æ · | scipy.signal.resample | scipy.signal.resample | âœ… ä¸€è‡´ |
| æ»¤æ³¢ç±»å‹ | lfilter (å› æœ) | lfilter (å› æœ) | âœ… ä¸€è‡´ |
| æ»¤æ³¢é˜¶æ•° | 4é˜¶ Butterworth | 4é˜¶ Butterworth | âœ… ä¸€è‡´ |
| æ»¤æ³¢é¢‘å¸¦ | [4, 40] Hz | [4, 40] Hz | âœ… ä¸€è‡´ |
| æ»¤æ³¢ padding | 100 samples | 100 samples | âœ… ä¸€è‡´ |
| Z-score è½´ | axis=2 (æ—¶é—´) | axis=-1 (æ—¶é—´) | âœ… ä¸€è‡´ |

**é¢„å¤„ç†å®Œå…¨å¯¹é½** âœ…

---

## è®­ç»ƒé…ç½®

### åŸè®ºæ–‡è®­ç»ƒé…ç½®

**æ–‡ä»¶**: `Functions.py:150-260`, `main_model_training.py:41-48`

```python
# å‚æ•°è®¾ç½® (main_model_training.py:42-48)
params = {
    'maxtriallen': 5,          # 5s offline trials
    'windowlen': 1,            # 1s sliding window
    'block_size': 128,         # step size
    'downsrate': 100,          # é™é‡‡æ ·è‡³ 100 Hz
    'bandpass_filt': [4, 40],  # 4-40 Hz
    'nclass': nclass
}

# è®­ç»ƒé…ç½® (Functions.py:204)
batch_size, epochs = 16, 300

# ä¼˜åŒ–å™¨ (Functions.py:229-232)
if finetune:
    optimizer = Adam(learning_rate=1e-4)
else:
    optimizer = Adam(learning_rate=0.001)

# Callbacks (Functions.py:226-227)
callback_es = EarlyStopping(monitor='val_loss', patience=80)
callback_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=30)

# å¾®è°ƒ (Functions.py:243-253)
if finetune:
    epochs = 100
    dropout_rate = 0.65
    layers_fine_tune = 12  # å†»ç»“å‰ (num_layers - 12) å±‚
```

### æœ¬ä»“åº“å®ç°

**æ–‡ä»¶**: `configs/eegnet_config.yaml`, `src/training/train_within_subject.py`

```yaml
# configs/eegnet_config.yaml
training:
  epochs: 300
  batch_size: 64           # åŸè®ºæ–‡: 16
  learning_rate: 1.0e-3
  weight_decay: 0
  early_stopping: true
  patience: 4              # åŸè®ºæ–‡: 80
  min_delta: 0.001
  scheduler: plateau       # ReduceLROnPlateau
```

```python
# src/training/train_within_subject.py:264-275
elif scheduler_type == 'plateau':
    self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        self.optimizer,
        mode='min',
        factor=0.5,          # ä¸åŸè®ºæ–‡ä¸€è‡´
        patience=30,         # ä¸åŸè®ºæ–‡ä¸€è‡´
        min_lr=1e-6,
    )
```

### è®­ç»ƒé…ç½®å·®å¼‚åˆ†æ

| é…ç½®é¡¹ | åŸè®ºæ–‡ | æœ¬ä»“åº“ | å·®å¼‚è¯´æ˜ |
|--------|--------|--------|----------|
| **Batch Size** | **16** | **64** | âš ï¸ æœ¬ä»“åº“ 4x |
| Epochs | 300 | 300 | âœ… ä¸€è‡´ |
| Learning Rate | 1e-3 | 1e-3 | âœ… ä¸€è‡´ |
| Weight Decay | æœªæ˜ç¡® | 0 | âœ… æ ‡å‡†å€¼ |
| **Early Stopping** | **patience=80** | **patience=4-5** | âš ï¸ å·®å¼‚æ˜¾è‘— |
| LR Scheduler | ReduceLROnPlateau | ReduceLROnPlateau | âœ… ä¸€è‡´ |
| LR Factor | 0.5 | 0.5 | âœ… ä¸€è‡´ |
| LR Patience | 30 | 30 | âœ… ä¸€è‡´ |

**å…³é”®å·®å¼‚**:
1. **Batch Size**: åŸè®ºæ–‡ 16ï¼Œæœ¬ä»“åº“ 64 (4x)
2. **Early Stopping Patience**: åŸè®ºæ–‡ 80 epochsï¼Œæœ¬ä»“åº“ 4-5 epochs

---

## æ•°æ®åˆ’åˆ†åè®®

### åŸè®ºæ–‡åè®®

**æ–‡ä»¶**: `Functions.py:50-78`, `Functions.py:160-170`

```python
# æ•°æ®ç”Ÿæˆ (generate_paths)
if model_type == 'Finetune':
    # åªä½¿ç”¨å½“å¤©çš„ Base runs
    pattern = f'{prefix}_Sess{session_num:02}*Base'
else:
    # Offline + ä¹‹å‰æ‰€æœ‰ Online sessions
    offline_pattern = f'{prefix}'  # OfflineImagery æˆ– OfflineMovement
    for session in range(1, session_num):
        online_pattern = f'{prefix}_Sess{session:02}*'

# åˆ’åˆ†æ–¹æ³• (train_models, line 160-170)
shuffled_idx = np.random.permutation(nTrial)
train_percent = 0.8
train_idx = shuffled_idx[:int(train_percent*nTrial)]
val_idx = np.setdiff1d(shuffled_idx, train_idx)
```

**å…³é”®**: åŸè®ºæ–‡ä½¿ç”¨**éšæœºæ‰“ä¹±**åˆ’åˆ† (80/20)

### æœ¬ä»“åº“å®ç°

**æ–‡ä»¶**: `src/training/train_within_subject.py`, `CLAUDE.md`

```
è®­ç»ƒæ•°æ®:
â”œâ”€â”€ OfflineImagery (30 runs)
â”œâ”€â”€ OnlineImagery_Sess01_Xclass_Base (8 runs)
â”œâ”€â”€ OnlineImagery_Sess01_Xclass_Finetune (8 runs)
â””â”€â”€ OnlineImagery_Sess02_Xclass_Base (8 runs)
    â†“
    åˆ†å±‚æ—¶åºåˆ†å‰² (Stratified Temporal Split)
    â†“
â”œâ”€â”€ Train (å‰ 80% trials)
â””â”€â”€ Val (å 20% trials)

æµ‹è¯•æ•°æ® (å®Œå…¨ç‹¬ç«‹):
â””â”€â”€ OnlineImagery_Sess02_Xclass_Finetune (8 runs)
```

**å…³é”®**:
- Train/Val åˆ’åˆ†ï¼šä½¿ç”¨**æ—¶åºåˆ†å‰²**ï¼ˆéªŒè¯é›†å–æœ«å°¾ 20%ï¼‰ï¼Œé¿å…æ•°æ®æ³„éœ²
- è®­ç»ƒæ—¶ shuffleï¼š**å¯ç”¨** (`shuffle=True`)ï¼Œä¸åŸè®ºæ–‡ä¸€è‡´

### æ•°æ®åˆ’åˆ†å·®å¼‚åˆ†æ

| æ–¹é¢ | åŸè®ºæ–‡ | æœ¬ä»“åº“ | å·®å¼‚è¯´æ˜ |
|------|--------|--------|----------|
| åˆ’åˆ†æ¯”ä¾‹ | 80/20 | 80/20 | âœ… ä¸€è‡´ |
| **Train/Val åˆ’åˆ†** | **éšæœºæ‰“ä¹±ååˆ’åˆ†** | **æ—¶åºåˆ’åˆ† (æœ«å°¾20%)** | âš ï¸ å·®å¼‚ |
| è®­ç»ƒæ—¶ shuffle | æ˜¯ (æ¯ epoch) | æ˜¯ (æ¯ epoch) | âœ… ä¸€è‡´ |
| è®­ç»ƒæ•°æ® | Offline + prior Online | Offline + Sess01 + Sess02 Base | âœ… ç±»ä¼¼ |
| æµ‹è¯•æ•°æ® | Finetune runs | Sess02 Finetune | âœ… ä¸€è‡´ |
| è¯„ä¼°æ–¹å¼ | Majority Voting | Majority Voting | âœ… ä¸€è‡´ |

**å…³äºåˆ’åˆ†æ–¹æ³•å·®å¼‚**:
- åŸè®ºæ–‡ï¼šéšæœºæ‰“ä¹±æ‰€æœ‰ trials åå– 80/20ï¼ŒéªŒè¯é›†å¯èƒ½åŒ…å«æ—¶é—´ä¸Šè¾ƒæ—©çš„ trials
- æœ¬ä»“åº“ï¼šéªŒè¯é›†å›ºå®šä¸ºæ—¶é—´ä¸Šæœ€å 20% çš„ trialsï¼Œæ›´ä¸¥æ ¼åœ°æ¨¡æ‹ŸçœŸå® BCI åœºæ™¯
- **è®­ç»ƒæ—¶ä¸¤è€…éƒ½ä½¿ç”¨ shuffle**ï¼ŒåŒºåˆ«ä»…åœ¨äºéªŒè¯é›†çš„é€‰å–æ–¹å¼

---

## æ€§èƒ½ä¼˜åŒ– (æœ¬ä»“åº“æ–°å¢)

æœ¬ä»“åº“ç›¸æ¯”åŸè®ºæ–‡å®ç°å¢åŠ äº†ä»¥ä¸‹æ€§èƒ½ä¼˜åŒ–:

### 1. cuDNN è‡ªåŠ¨è°ƒä¼˜

**æ–‡ä»¶**: `src/training/train_within_subject.py`

```python
if device.type == 'cuda':
    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.deterministic = False
```

**æ•ˆæœ**: è®­ç»ƒé€Ÿåº¦æå‡ 20-50%

### 2. è‡ªåŠ¨æ··åˆç²¾åº¦ (AMP)

```python
if self.use_amp:
    with torch.amp.autocast('cuda', dtype=torch.float16):
        outputs = self.model(segments)
        loss = self.criterion(outputs, labels)
    self.scaler.scale(loss).backward()
```

**æ•ˆæœ**: æ˜¾å­˜å‡å°‘ï¼Œé€Ÿåº¦æå‡ 10-20%

### 3. torch.compile() æ”¯æŒ

```python
if use_compile and hasattr(torch, 'compile') and device.type == 'cuda':
    model = torch.compile(model, mode='reduce-overhead')
```

**æ•ˆæœ**: é€Ÿåº¦æå‡ 10-30% (PyTorch 2.0+)

### 4. é¢„å¤„ç†ç¼“å­˜

**æ–‡ä»¶**: `src/preprocessing/cache_manager.py`

- HDF5 æ ¼å¼ç¼“å­˜ (lzf å‹ç¼©)
- é¦–æ¬¡åŠ è½½å 3-6x åŠ é€Ÿ
- è‡ªåŠ¨å¤±æ•ˆæ£€æµ‹

### 5. å¹¶è¡Œé¢„å¤„ç†

```python
dataset = FingerEEGDataset(..., parallel_workers=0)  # è‡ªåŠ¨å¤šæ ¸
```

**æ•ˆæœ**: é¦–æ¬¡åŠ è½½åŠ é€Ÿ 2-3x

---

## æ¨¡å‹è¯„ä¼°

### åŸè®ºæ–‡ç»“æœ

| ä»»åŠ¡ | å‡†ç¡®ç‡ (Majority Voting) |
|------|-------------------------|
| 2-finger MI | 80.56% |
| 3-finger MI | 60.61% |
| 2-finger ME | 81.10% |
| 3-finger ME | 60.11% |

### æœ¬ä»“åº“é¢„æœŸ

ç”±äºå­˜åœ¨ä»¥ä¸‹å·®å¼‚ï¼Œç»“æœå¯èƒ½ç•¥æœ‰ä¸åŒï¼š
1. **kernLength**: 64 vs 32 (å½±å“æ—¶é—´æ„Ÿå—é‡)
2. **Batch Size**: 64 vs 16 (å½±å“æ¢¯åº¦ä¼°è®¡)
3. **Early Stopping**: 5 vs 80 (å¯èƒ½æå‰åœæ­¢)
4. **åˆ’åˆ†æ–¹æ³•**: æ—¶åº vs éšæœº (æ›´ä¸¥æ ¼è¯„ä¼°)

---

## å…³é”®å·®å¼‚æ€»ç»“

### âœ… å®Œå…¨ä¸€è‡´çš„æ–¹é¢

1. æ¨¡å‹æ¶æ„æ ¸å¿ƒ (EEGNet-8,2: F1=8, D=2, F2=16)
2. é¢„å¤„ç†æµç¨‹ (CAR â†’ æ»‘åŠ¨çª—å£ â†’ é™é‡‡æ · â†’ æ»¤æ³¢ â†’ Z-score)
3. æ»¤æ³¢å‚æ•° (4-40 Hz, 4é˜¶ Butterworth, lfilter)
4. æ»‘åŠ¨çª—å£å‚æ•° (1s çª—å£, 128 samples æ­¥é•¿)
5. å½’ä¸€åŒ–æ–¹æ³• (Z-score æ²¿æ—¶é—´è½´)
6. è®­ç»ƒ epochs (300)
7. LR Scheduler (ReduceLROnPlateau, factor=0.5, patience=30)

### âš ï¸ å­˜åœ¨å·®å¼‚çš„æ–¹é¢

| å·®å¼‚é¡¹ | åŸè®ºæ–‡ | æœ¬ä»“åº“ | å½±å“ |
|--------|--------|--------|------|
| æ·±åº¦å­¦ä¹ æ¡†æ¶ | TensorFlow | PyTorch | ä½ |
| kernLength | 32 | 64 | ä¸­ (æ—¶é—´æ„Ÿå—é‡) |
| Batch Size | 16 | 64 | ä¸­ (æ¢¯åº¦ä¼°è®¡) |
| Early Stopping | patience=80 | patience=4-5 | é«˜ (å¯èƒ½æå‰åœæ­¢) |
| Val åˆ’åˆ†æ–¹å¼ | éšæœºåˆ’åˆ† | æ—¶åºåˆ’åˆ† (æœ«å°¾20%) | ä¸­ (è¯„ä¼°æ›´ä¸¥æ ¼) |
| Dense constraint | max_norm(0.25) | æ—  | ä½ |
| è®­ç»ƒ shuffle | æ˜¯ | æ˜¯ | âœ… ä¸€è‡´ |

### ğŸš€ æœ¬ä»“åº“å¢å¼º

1. æ€§èƒ½ä¼˜åŒ–: AMP, torch.compile, cuDNN benchmark
2. é¢„å¤„ç†ç¼“å­˜: HDF5 + å¹¶è¡ŒåŠ è½½
3. æ—¶åºéªŒè¯é›†åˆ’åˆ†: é¿å…æ•°æ®æ³„éœ²
4. Trial-level åˆ†å‰²: æ›´ä¸¥æ ¼çš„è¯„ä¼°

---

## å»ºè®®çš„æ”¹è¿›æ–¹å‘

1. **å¯¹é½ kernLength**: æ”¹ä¸º 32 ä»¥å®Œå…¨åŒ¹é…åŸè®ºæ–‡
2. **å¯¹é½ Batch Size**: è€ƒè™‘ä½¿ç”¨ 16 è¿›è¡Œå¯¹æ¯”å®éªŒ
3. **å¯¹é½ Early Stopping**: å¢åŠ  patience è‡³ 80
4. **æ·»åŠ  Dense constraint**: å®ç° max_norm(0.25)
5. **å®éªŒå¯¹æ¯”**: åœ¨ä¸¤ç§é…ç½®ä¸‹è¿è¡Œï¼Œé‡åŒ–å·®å¼‚å½±å“

---

## é…ç½®æ–‡ä»¶å‚è€ƒ

### EEGNet é…ç½® (`configs/eegnet_config.yaml`)

```yaml
model:
  name: EEGNet-8,2
  F1: 8
  D: 2
  F2: 16
  kernel_length: 64       # åŸè®ºæ–‡: 32
  dropout_rate: 0.5

data:
  sampling_rate: 100
  n_channels: 128
  bandpass_low: 4.0
  bandpass_high: 40.0

training:
  epochs: 300
  batch_size: 64          # åŸè®ºæ–‡: 16
  learning_rate: 1.0e-3
  patience: 4             # åŸè®ºæ–‡: 80
  scheduler: plateau
```

### é¢„å¤„ç†é…ç½® (`PreprocessConfig.paper_aligned()`)

```python
PreprocessConfig(
    target_model='eegnet',
    original_fs=1024,
    target_fs=100,
    bandpass_low=4.0,
    bandpass_high=40.0,
    filter_order=4,
    channel_strategy='C',      # å…¨éƒ¨ 128 é€šé“
    segment_length=1.0,        # 1s çª—å£
    segment_step_samples=128,  # 125ms @ 1024 Hz
    normalize_method='zscore_time',
    apply_car=True,
    filter_padding=100,
)
```

---

## å‚è€ƒæ–‡çŒ®

1. Ding et al., "EEG-based brain-computer interface enables real-time robotic hand control at individual finger level", Nature Communications, 2025
2. Lawhern et al., "EEGNet: A Compact Convolutional Neural Network for EEG-based Brain-Computer Interfaces", J. Neural Eng., 2018
3. åŸè®ºæ–‡ä»£ç : https://github.com/bfinl/Finger-BCI-Decoding
4. åŸè®ºæ–‡æ•°æ®: https://doi.org/10.1184/R1/29104040

---

*æ–‡æ¡£æ›´æ–°æ—¥æœŸ: 2026-01-08*
